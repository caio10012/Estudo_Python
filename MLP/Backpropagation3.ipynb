{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Backpropagation",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caio10012/Estudo_Python/blob/main/MLP/Backpropagation3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gquVOlEzAIeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa00d96-a44e-400d-95ee-4754d1f88f6d"
      },
      "source": [
        "!git clone https://github.com/valmirf/redes_neurais_pos.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'redes_neurais_pos'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 120 (delta 11), reused 1 (delta 0), pack-reused 90 (from 1)\u001b[K\n",
            "Receiving objects: 100% (120/120), 16.66 MiB | 10.35 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJEk_jQrrJXn"
      },
      "source": [
        "##Multipayer Perceptron (MLP)\n",
        "\n",
        "Rede Neural baseado no algoritmo de gradiente descendente.  \n",
        "Os gradientes s√£o calculados usando backpropagation.\n",
        "\n",
        "Para mais detalhes, ver os capitulos 13 a 16 do livro no site:\n",
        "\n",
        "http://deeplearningbook.com.br/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNeeLtK58tGe"
      },
      "source": [
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o de Ativa√ß√£o ReLU\n",
        "def relu(net):\n",
        "    return np.maximum(0, net)\n",
        "\n",
        "# Fun√ß√£o para retornar as derivadas da fun√ß√£o ReLU\n",
        "def relu_prime(z):\n",
        "    return np.where(z > 0, 1.0, 0.0)\n"
      ],
      "metadata": {
        "id": "nSm5uH1kbDWR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPjNMuBE8UcP"
      },
      "source": [
        "A entrada √© uma lista (`sizes`) cont√©m o n√∫mero de neur√¥nios nas respectivas camadas da rede. Por exemplo, se a lista for [2, 3, 1] ent√£o ser√° uma rede de tr√™s camadas, com o primeira camada contendo 2 neur√¥nios, a segunda camada 3 neur√¥nios, e a terceira camada 1 neur√¥nio. Os bias e pesos para a rede s√£o inicializados aleatoriamente, usando uma distribui√ß√£o Gaussiana com m√©dia 0 e vari√¢ncia 1. Note que a primeira camada √© assumida como uma camada de entrada, e por conven√ß√£o n√£o definimos nenhum bias para esses neur√¥nios, pois os bias s√£o usados na computa√ß√£o das sa√≠das das camadas posteriores.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classe Network modificada para usar ReLU\n",
        "class Network(object):\n",
        "\n",
        "    def __init__(self, sizes):\n",
        "        self.num_layers = len(sizes)  # n√∫mero de neur√¥nios em cada camada\n",
        "        self.sizes = sizes\n",
        "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]  # limiar\n",
        "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]  # pesos\n",
        "\n",
        "    def feedforward(self, x):\n",
        "        \"\"\"Retorna a sa√≠da da rede z se `x` for entrada.\"\"\"\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            x = relu(np.dot(w, x) + b)  # usar ReLU em vez de sigmoid\n",
        "        return x\n",
        "\n",
        "    def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
        "        \"\"\"Treinar a rede neural usando o algoritmo mini batch com gradiente descendente.\"\"\"\n",
        "        training_data = list(training_data)\n",
        "        n = len(training_data)\n",
        "\n",
        "        if test_data:\n",
        "            test_data = list(test_data)\n",
        "            n_test = len(test_data)\n",
        "\n",
        "        for j in range(epochs):\n",
        "            random.shuffle(training_data)\n",
        "            mini_batches = [training_data[k:k + mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
        "            for mini_batch in mini_batches:\n",
        "                self.update_mini_batch(mini_batch, eta)\n",
        "            if test_data:\n",
        "                acc = self.evaluate(test_data)\n",
        "                print(\"Epoch {} : {} / {} = {}%\".format(j, acc, n_test, (acc * 100) / n_test))\n",
        "            else:\n",
        "                print(\"Epoch {} finalizada\".format(j))\n",
        "\n",
        "    def update_mini_batch(self, mini_batch, eta):\n",
        "        \"\"\"Atualiza os pesos e limiares da rede aplicando a descida do gradiente usando backpropagation para um √∫nico mini lote.\"\"\"\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "\n",
        "        self.weights = [w - (eta / len(mini_batch)) * nw for w, nw in zip(self.weights, nabla_w)]\n",
        "        self.biases = [b - (eta / len(mini_batch)) * nb for b, nb in zip(self.biases, nabla_b)]\n",
        "\n",
        "    def backprop(self, x, y):\n",
        "        \"\"\"Retorna uma tupla `(nabla_b, nabla_w)` representando o gradiente para a fun√ß√£o de custo J_x.\"\"\"\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "\n",
        "        activation = x\n",
        "        activations = [x]\n",
        "        nets = []\n",
        "\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            net = np.dot(w, activation) + b\n",
        "            nets.append(net)\n",
        "            activation = relu(net)  # usar ReLU em vez de sigmoid\n",
        "            activations.append(activation)\n",
        "\n",
        "        delta = self.cost_derivative(activations[-1], y) * relu_prime(nets[-1])  # usar derivada de ReLU em vez de sigmoid_prime\n",
        "        nabla_b[-1] = delta\n",
        "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
        "\n",
        "        for l in range(2, self.num_layers):\n",
        "            net = nets[-l]\n",
        "            zs = relu_prime(net)  # usar derivada de ReLU em vez de sigmoid_prime\n",
        "            delta = np.dot(self.weights[-l + 1].transpose(), delta) * zs\n",
        "            nabla_b[-l] = delta\n",
        "            nabla_w[-l] = np.dot(delta, activations[-l - 1].transpose())\n",
        "        return (nabla_b, nabla_w)\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        \"\"\"Retorna o n√∫mero de entradas de teste para as quais a rede neural produz o resultado correto.\"\"\"\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
        "        return sum(int(x == y) for (x, y) in test_results)\n",
        "\n",
        "    def cost_derivative(self, output_activations, y):\n",
        "        \"\"\"Retorna o vetor das derivadas parciais.\"\"\"\n",
        "        return (output_activations - y)\n"
      ],
      "metadata": {
        "id": "azpWdmcnbUNP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGf77mI_vuzP"
      },
      "source": [
        "# Classe Network\n",
        "class Network(object):\n",
        "\n",
        "    def __init__(self, sizes):\n",
        "        self.num_layers = len(sizes)  #n√∫mero de neur√¥nios em cada camada\n",
        "        self.sizes = sizes\n",
        "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]] #limiar\n",
        "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])] #pesos\n",
        "\n",
        "    def feedforward(self, x):\n",
        "        \"\"\"Retorna a sa√≠da da rede z se `x` for entrada.\"\"\"\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            x = sigmoid(np.dot(w, x)+b) #net = (‚àëxw+b)\n",
        "        return x\n",
        "\n",
        "    def SGD(self, training_data, epochs, mini_batch_size, ùúÇ, test_data=None):\n",
        "        \"\"\"Treinar a rede neural usando o algoritmo mini batch com gradiente descendente.\n",
        "         A entrada √© uma lista de tuplas\n",
        "         `(x, y)` representando as entradas de treinamento e as\n",
        "         sa√≠das. Os outros par√¢metros n√£o opcionais s√£o\n",
        "         auto-explicativos. Se `test_data` for fornecido, ent√£o a\n",
        "         rede ser√° avaliada em rela√ß√£o aos dados do teste ap√≥s cada\n",
        "         √©poca e progresso parcial impresso. Isso √© √∫til para\n",
        "         acompanhar o progresso, mas retarda as coisas substancialmente.\"\"\"\n",
        "\n",
        "        #dataset de treino\n",
        "        training_data = list(training_data)\n",
        "        n = len(training_data)\n",
        "\n",
        "        #dataset de teste\n",
        "        if test_data:\n",
        "            test_data = list(test_data)\n",
        "            n_test = len(test_data)\n",
        "\n",
        "        for j in range(epochs):\n",
        "            random.shuffle(training_data)\n",
        "            #t√©cnica que realiza o treinamento por lotes\n",
        "            #mini_batch_size = tamanho do lote\n",
        "            mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
        "\n",
        "            for mini_batch in mini_batches:\n",
        "                self.update_mini_batch(mini_batch, ùúÇ)\n",
        "\n",
        "            if test_data:\n",
        "                acc = self.evaluate(test_data)\n",
        "                print(\"Epoch {} : {} / {} = {}%\".format(j,acc,n_test,(acc*100)/n_test));\n",
        "\n",
        "            else:\n",
        "                print(\"Epoch {} finalizada\".format(j))\n",
        "\n",
        "    def update_mini_batch(self, mini_batch, ùúÇ):\n",
        "        \"\"\"Atualiza os pesos e limiares da rede aplicando\n",
        "         a descida do gradiente usando backpropagation para um √∫nico mini lote.\n",
        "         O `mini_batch` √© uma lista de tuplas `(x, y)`, e `a` √© a taxa de aprendizado.\"\"\"\n",
        "\n",
        "        #inicializa matriz com derivadas de pesos e limiares\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "\n",
        "        for x, y in mini_batch:\n",
        "            #resultado dos deltas do backpropagation sem a multiplica√ß√£o da taxa de aprendizagem\n",
        "            #soma os deltas do minibatch\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "\n",
        "        #atualiza pesos e limiares (ùúÇ*ùõø*f‚Äô(net)*ùë•)\n",
        "        self.weights = [w-(ùúÇ/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)]\n",
        "        self.biases = [b-(ùúÇ/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)]\n",
        "\n",
        "    def backprop(self, x, y):\n",
        "        \"\"\"Retorna uma tupla `(nabla_b, nabla_w)` representando o\n",
        "         gradiente para a fun√ß√£o de custo J_x. `nabla_b` e\n",
        "         `nabla_w` s√£o listas de camadas de matrizes numpy, semelhantes\n",
        "         a `self.biases` e `self.weights`.\"\"\"\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "\n",
        "        # Feedforward\n",
        "        activation = x\n",
        "\n",
        "        # Lista para armazenar todas as sa√≠das dos neur√¥nios (z), camada por camada\n",
        "        activations = [x]\n",
        "\n",
        "        # Lista para armazenar todos os vetores net, camada por camada\n",
        "        nets = []\n",
        "\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            net = np.dot(w, activation)+b\n",
        "            nets.append(net)\n",
        "            activation = sigmoid(net) #z = valor de sa√≠da do neur√¥nio\n",
        "            activations.append(activation)\n",
        "\n",
        "        # Backward pass\n",
        "\n",
        "        #√∫ltima camada -(u-z)f'(net)\n",
        "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(nets[-1])\n",
        "        nabla_b[-1] = delta\n",
        "        nabla_w[-1] = np.dot(delta, activations[-2].transpose()) #(ùë¶‚àíùëß)*f‚Äô(net)*ùë•\n",
        "\n",
        "        # l = 1 significa a √∫ltima camada de neur√¥nios, l = 2 √© a pen√∫ltima e assim por diante.\n",
        "        for l in range(2, self.num_layers):\n",
        "            net = nets[-l]\n",
        "            zs = sigmoid_prime(net)\n",
        "            #delta da camada intermediaria. Note que utiliza o delta calculado anteriormente\n",
        "            delta = np.dot(self.weights[-l+1].transpose(), delta) * zs\n",
        "            nabla_b[-l] = delta\n",
        "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose()) #‚àë(ùõøùë§)f‚Äô(net)ùë•\n",
        "        return (nabla_b, nabla_w)\n",
        "\n",
        "    def evaluate(self, test_data):\n",
        "        \"\"\"Retorna o n√∫mero de entradas de teste para as quais a rede neural\n",
        "         produz o resultado correto. Note que a sa√≠da da rede neural\n",
        "         √© considerada o √≠ndice de qualquer que seja\n",
        "         neur√¥nio na camada final que tenha a maior ativa√ß√£o.\"\"\"\n",
        "\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]\n",
        "        return sum(int(x == y) for (x, y) in test_results)\n",
        "\n",
        "    def cost_derivative(self, output_activations, y):\n",
        "        \"\"\"Retorna o vetor das derivadas parciais.\"\"\"\n",
        "        return (output_activations-y)\n",
        "\n",
        "# Fun√ß√£o de Ativa√ß√£o Sigm√≥ide\n",
        "def sigmoid(net):\n",
        "    return 1.0/(1.0+np.exp(-net))\n",
        "\n",
        "# Fun√ß√£o para retornar as derivadas da fun√ß√£o Sigm√≥ide\n",
        "def sigmoid_prime(z):\n",
        "    return sigmoid(z)*(1-sigmoid(z))\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lndK7bt9F6d"
      },
      "source": [
        "Como exemplo, essa mesma rede ser√° executada na base de dados MNIST. O codigo abaixo carrega a base de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOZwqOkDv3t-"
      },
      "source": [
        "# Carregar o dataset MNIST\n",
        "\n",
        "# Imports\n",
        "import pickle\n",
        "import gzip\n",
        "import numpy as np\n",
        "\n",
        "def load_data():\n",
        "    f = gzip.open('redes_neurais_pos/MLP/mnist.pkl.gz', 'rb')\n",
        "    training_data, validation_data, test_data = pickle.load(f, encoding=\"latin1\")\n",
        "    f.close()\n",
        "    return (training_data, validation_data, test_data)\n",
        "\n",
        "def load_data_wrapper():\n",
        "    tr_d, va_d, te_d = load_data()\n",
        "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
        "    training_results = [vectorized_result(y) for y in tr_d[1]]\n",
        "    training_data = zip(training_inputs, training_results)\n",
        "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
        "    validation_data = zip(validation_inputs, va_d[1])\n",
        "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
        "    test_data = zip(test_inputs, te_d[1])\n",
        "    return (training_data, validation_data, test_data)\n",
        "\n",
        "def vectorized_result(j):\n",
        "    e = np.zeros((10, 1))\n",
        "    e[j] = 1.0\n",
        "    return e\n",
        "\n",
        "# Carregar dados\n",
        "training_data, validation_data, test_data = load_data_wrapper()\n",
        "training_data = list(training_data)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Definir a arquitetura da rede com uma camada intermedi√°ria\n",
        "arquitetura = [784, 200, 10]\n",
        "\n",
        "# Taxa de aprendizado a ser testada\n",
        "taxa_aprendizado = 0.3\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: Sigmoid\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o Sigmoid\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_sigmoid = Network(arquitetura)\n",
        "rede_sigmoid.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: ReLU\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o ReLU\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_relu = Network(arquitetura)\n",
        "rede_relu.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)\n"
      ],
      "metadata": {
        "id": "WI_KgJVQdw8h",
        "outputId": "3a3cb80a-6eaa-4484-b120-1ad5bbb1851a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando fun√ß√£o de ativa√ß√£o Sigmoid\n",
            "Treinando com taxa de aprendizagem: 0.3\n",
            "Epoch 0 : 2881 / 10000 = 28.81%\n",
            "Epoch 1 : 3063 / 10000 = 30.63%\n",
            "Epoch 2 : 3115 / 10000 = 31.15%\n",
            "Epoch 3 : 3191 / 10000 = 31.91%\n",
            "Epoch 4 : 3294 / 10000 = 32.94%\n",
            "Epoch 5 : 3583 / 10000 = 35.83%\n",
            "Epoch 6 : 3922 / 10000 = 39.22%\n",
            "Epoch 7 : 4037 / 10000 = 40.37%\n",
            "Epoch 8 : 4128 / 10000 = 41.28%\n",
            "Epoch 9 : 4237 / 10000 = 42.37%\n",
            "Testando fun√ß√£o de ativa√ß√£o ReLU\n",
            "Treinando com taxa de aprendizagem: 0.3\n",
            "Epoch 0 : 1793 / 10000 = 17.93%\n",
            "Epoch 1 : 1846 / 10000 = 18.46%\n",
            "Epoch 2 : 1888 / 10000 = 18.88%\n",
            "Epoch 3 : 1927 / 10000 = 19.27%\n",
            "Epoch 4 : 1989 / 10000 = 19.89%\n",
            "Epoch 5 : 2060 / 10000 = 20.6%\n",
            "Epoch 6 : 2160 / 10000 = 21.6%\n",
            "Epoch 7 : 2374 / 10000 = 23.74%\n",
            "Epoch 8 : 2619 / 10000 = 26.19%\n",
            "Epoch 9 : 2755 / 10000 = 27.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precisoes_sigmoide = [28.81, 30.63, 31.15, 31.91, 32.94, 35.83, 39.22, 40.37, 41.28, 42.37]\n",
        "media_sigmoide = sum(precisoes_sigmoide) / len(precisoes_sigmoide)\n",
        "print(f\"M√©dia de Precis√£o Sigmoide: {media_sigmoide:.2f}%\")\n",
        "precisoes_relu = [17.93, 18.46, 18.88, 19.27, 19.89, 20.60, 21.60, 23.74, 26.19, 27.55]\n",
        "media_relu = sum(precisoes_relu) / len(precisoes_relu)\n",
        "print(f\"M√©dia de Precis√£o ReLU: {media_relu:.2f}%\")\n"
      ],
      "metadata": {
        "id": "DZ5rb_MHj20W",
        "outputId": "3baea17d-c2d3-45cb-eca8-ef5a4eb30425",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©dia de Precis√£o Sigmoide: 35.45%\n",
            "M√©dia de Precis√£o ReLU: 21.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura da rede com uma camada intermedi√°ria\n",
        "arquitetura = [784, 200, 10]\n",
        "\n",
        "# Taxa de aprendizado a ser testada\n",
        "taxa_aprendizado = 0.1\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: Sigmoid\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o Sigmoid\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_sigmoid = Network(arquitetura)\n",
        "rede_sigmoid.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: ReLU\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o ReLU\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_relu = Network(arquitetura)\n",
        "rede_relu.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)"
      ],
      "metadata": {
        "id": "u4X4dmkQkmDR",
        "outputId": "35c7d681-971c-4d51-db4a-5a728b88097c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando fun√ß√£o de ativa√ß√£o Sigmoid\n",
            "Treinando com taxa de aprendizagem: 0.1\n",
            "Epoch 0 : 3194 / 10000 = 31.94%\n",
            "Epoch 1 : 3872 / 10000 = 38.72%\n",
            "Epoch 2 : 4127 / 10000 = 41.27%\n",
            "Epoch 3 : 4259 / 10000 = 42.59%\n",
            "Epoch 4 : 4353 / 10000 = 43.53%\n",
            "Epoch 5 : 4425 / 10000 = 44.25%\n",
            "Epoch 6 : 4471 / 10000 = 44.71%\n",
            "Epoch 7 : 4517 / 10000 = 45.17%\n",
            "Epoch 8 : 4541 / 10000 = 45.41%\n",
            "Epoch 9 : 4579 / 10000 = 45.79%\n",
            "Testando fun√ß√£o de ativa√ß√£o ReLU\n",
            "Treinando com taxa de aprendizagem: 0.1\n",
            "Epoch 0 : 3128 / 10000 = 31.28%\n",
            "Epoch 1 : 3765 / 10000 = 37.65%\n",
            "Epoch 2 : 4235 / 10000 = 42.35%\n",
            "Epoch 3 : 4494 / 10000 = 44.94%\n",
            "Epoch 4 : 4640 / 10000 = 46.4%\n",
            "Epoch 5 : 4759 / 10000 = 47.59%\n",
            "Epoch 6 : 4886 / 10000 = 48.86%\n",
            "Epoch 7 : 5100 / 10000 = 51.0%\n",
            "Epoch 8 : 5343 / 10000 = 53.43%\n",
            "Epoch 9 : 5497 / 10000 = 54.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precisoes_sigmoide = [31.94, 38.72, 41.27, 42.59, 43.53, 44.25, 44.71, 45.17, 45.41, 45.79]\n",
        "media_sigmoide = sum(precisoes_sigmoide) / len(precisoes_sigmoide)\n",
        "print(f\"M√©dia de Precis√£o Sigmoide: {media_sigmoide:.2f}%\")\n",
        "precisoes_relu = [31.28, 37.65, 42.35, 44.94, 46.40, 47.59, 48.86, 51.00, 53.43, 54.97]\n",
        "media_relu = sum(precisoes_relu) / len(precisoes_relu)\n",
        "print(f\"M√©dia de Precis√£o ReLU: {media_relu:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Nq72tRmulhGJ",
        "outputId": "a2aa0bc8-b70d-4287-c3d3-c212625223e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©dia de Precis√£o Sigmoide: 42.34%\n",
            "M√©dia de Precis√£o ReLU: 45.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura da rede com uma camada intermedi√°ria\n",
        "arquitetura = [784, 200, 10]\n",
        "\n",
        "# Taxa de aprendizado a ser testada\n",
        "taxa_aprendizado = 0.5\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: Sigmoid\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o Sigmoid\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_sigmoid = Network(arquitetura)\n",
        "rede_sigmoid.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: ReLU\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o ReLU\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_relu = Network(arquitetura)\n",
        "rede_relu.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)"
      ],
      "metadata": {
        "id": "BHYfXrl6lTM6",
        "outputId": "68ee5910-da78-4010-a9a1-997b49a9b407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando fun√ß√£o de ativa√ß√£o Sigmoid\n",
            "Treinando com taxa de aprendizagem: 0.5\n",
            "Epoch 0 : 4412 / 10000 = 44.12%\n",
            "Epoch 1 : 5139 / 10000 = 51.39%\n",
            "Epoch 2 : 5510 / 10000 = 55.1%\n",
            "Epoch 3 : 5630 / 10000 = 56.3%\n",
            "Epoch 4 : 6028 / 10000 = 60.28%\n",
            "Epoch 5 : 6209 / 10000 = 62.09%\n",
            "Epoch 6 : 6280 / 10000 = 62.8%\n",
            "Epoch 7 : 6331 / 10000 = 63.31%\n",
            "Epoch 8 : 6466 / 10000 = 64.66%\n",
            "Epoch 9 : 7036 / 10000 = 70.36%\n",
            "Testando fun√ß√£o de ativa√ß√£o ReLU\n",
            "Treinando com taxa de aprendizagem: 0.5\n",
            "Epoch 0 : 1858 / 10000 = 18.58%\n",
            "Epoch 1 : 2979 / 10000 = 29.79%\n",
            "Epoch 2 : 4111 / 10000 = 41.11%\n",
            "Epoch 3 : 4324 / 10000 = 43.24%\n",
            "Epoch 4 : 4433 / 10000 = 44.33%\n",
            "Epoch 5 : 4481 / 10000 = 44.81%\n",
            "Epoch 6 : 4522 / 10000 = 45.22%\n",
            "Epoch 7 : 5284 / 10000 = 52.84%\n",
            "Epoch 8 : 5411 / 10000 = 54.11%\n",
            "Epoch 9 : 5457 / 10000 = 54.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precisoes_sigmoide = [44.12, 51.39, 55.10, 56.30, 60.28, 62.09, 62.80, 63.31, 64.66, 70.36]\n",
        "media_sigmoide = sum(precisoes_sigmoide) / len(precisoes_sigmoide)\n",
        "print(f\"M√©dia de Precis√£o Sigmoide: {media_sigmoide:.2f}%\")\n",
        "precisoes_relu = [18.58, 29.79, 41.11, 43.24, 44.33, 44.81, 45.22, 52.84, 54.11, 54.57]\n",
        "media_relu = sum(precisoes_relu) / len(precisoes_relu)\n",
        "print(f\"M√©dia de Precis√£o ReLU: {media_relu:.2f}%\")\n"
      ],
      "metadata": {
        "id": "u_I5w8cnlcsW",
        "outputId": "286c9ae2-5a12-465f-a2b1-363847fdb941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©dia de Precis√£o Sigmoide: 59.04%\n",
            "M√©dia de Precis√£o ReLU: 42.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura da rede com uma camada intermedi√°ria\n",
        "arquitetura = [784, 16, 10]\n",
        "\n",
        "# Taxa de aprendizado a ser testada\n",
        "taxa_aprendizado = 0.1\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: Sigmoid\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o Sigmoid\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_sigmoid = Network(arquitetura)\n",
        "rede_sigmoid.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: ReLU\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o ReLU\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_relu = Network(arquitetura)\n",
        "rede_relu.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)"
      ],
      "metadata": {
        "id": "he4ZnFrirdqp",
        "outputId": "db49c670-73e3-4cba-b8bb-e100aa7e6ec4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando fun√ß√£o de ativa√ß√£o Sigmoid\n",
            "Treinando com taxa de aprendizagem: 0.1\n",
            "Epoch 0 : 2274 / 10000 = 22.74%\n",
            "Epoch 1 : 3592 / 10000 = 35.92%\n",
            "Epoch 2 : 4334 / 10000 = 43.34%\n",
            "Epoch 3 : 4881 / 10000 = 48.81%\n",
            "Epoch 4 : 5353 / 10000 = 53.53%\n",
            "Epoch 5 : 5758 / 10000 = 57.58%\n",
            "Epoch 6 : 6136 / 10000 = 61.36%\n",
            "Epoch 7 : 6415 / 10000 = 64.15%\n",
            "Epoch 8 : 6734 / 10000 = 67.34%\n",
            "Epoch 9 : 7048 / 10000 = 70.48%\n",
            "Testando fun√ß√£o de ativa√ß√£o ReLU\n",
            "Treinando com taxa de aprendizagem: 0.1\n",
            "Epoch 0 : 2608 / 10000 = 26.08%\n",
            "Epoch 1 : 3833 / 10000 = 38.33%\n",
            "Epoch 2 : 4782 / 10000 = 47.82%\n",
            "Epoch 3 : 5348 / 10000 = 53.48%\n",
            "Epoch 4 : 5664 / 10000 = 56.64%\n",
            "Epoch 5 : 5911 / 10000 = 59.11%\n",
            "Epoch 6 : 6148 / 10000 = 61.48%\n",
            "Epoch 7 : 6363 / 10000 = 63.63%\n",
            "Epoch 8 : 6640 / 10000 = 66.4%\n",
            "Epoch 9 : 6871 / 10000 = 68.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precisoes_sigmoide = [22.74, 35.92, 43.34, 48.81, 53.53, 57.58, 61.36, 64.15, 67.34, 70.48]\n",
        "media_sigmoide = sum(precisoes_sigmoide) / len(precisoes_sigmoide)\n",
        "print(f\"M√©dia de Precis√£o Sigmoide: {media_sigmoide:.2f}%\")\n",
        "precisoes_relu = [26.08, 38.33, 47.82, 53.48, 56.64, 59.11, 61.48, 63.63, 66.40, 68.71]\n",
        "media_relu = sum(precisoes_relu) / len(precisoes_relu)\n",
        "print(f\"M√©dia de Precis√£o ReLU: {media_relu:.2f}%\")\n"
      ],
      "metadata": {
        "id": "x0qQ5poGr5L7",
        "outputId": "5f13df57-e5b7-4626-d4b5-5a13f0572b8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©dia de Precis√£o Sigmoide: 52.53%\n",
            "M√©dia de Precis√£o ReLU: 54.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura da rede com uma camada intermedi√°ria\n",
        "arquitetura = [784, 16, 10]\n",
        "\n",
        "# Taxa de aprendizado a ser testada\n",
        "taxa_aprendizado = 0.3\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: Sigmoid\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o Sigmoid\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_sigmoid = Network(arquitetura)\n",
        "rede_sigmoid.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: ReLU\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o ReLU\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_relu = Network(arquitetura)\n",
        "rede_relu.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)"
      ],
      "metadata": {
        "id": "5OEK_gF4rzAa",
        "outputId": "ec93e396-c35e-4a3c-c758-166c6969c174",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando fun√ß√£o de ativa√ß√£o Sigmoid\n",
            "Treinando com taxa de aprendizagem: 0.3\n",
            "Epoch 0 : 4440 / 10000 = 44.4%\n",
            "Epoch 1 : 5765 / 10000 = 57.65%\n",
            "Epoch 2 : 6449 / 10000 = 64.49%\n",
            "Epoch 3 : 7520 / 10000 = 75.2%\n",
            "Epoch 4 : 7980 / 10000 = 79.8%\n",
            "Epoch 5 : 8182 / 10000 = 81.82%\n",
            "Epoch 6 : 8340 / 10000 = 83.4%\n",
            "Epoch 7 : 8446 / 10000 = 84.46%\n",
            "Epoch 8 : 8556 / 10000 = 85.56%\n",
            "Epoch 9 : 8625 / 10000 = 86.25%\n",
            "Testando fun√ß√£o de ativa√ß√£o ReLU\n",
            "Treinando com taxa de aprendizagem: 0.3\n",
            "Epoch 0 : 4781 / 10000 = 47.81%\n",
            "Epoch 1 : 6262 / 10000 = 62.62%\n",
            "Epoch 2 : 6606 / 10000 = 66.06%\n",
            "Epoch 3 : 7250 / 10000 = 72.5%\n",
            "Epoch 4 : 7554 / 10000 = 75.54%\n",
            "Epoch 5 : 7753 / 10000 = 77.53%\n",
            "Epoch 6 : 7862 / 10000 = 78.62%\n",
            "Epoch 7 : 7953 / 10000 = 79.53%\n",
            "Epoch 8 : 8017 / 10000 = 80.17%\n",
            "Epoch 9 : 8148 / 10000 = 81.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precis√µes Sigmoide\n",
        "precisoes_sigmoide = [44.40, 57.65, 64.49, 75.20, 79.80, 81.82, 83.40, 84.46, 85.56, 86.25]\n",
        "media_sigmoide = sum(precisoes_sigmoide) / len(precisoes_sigmoide)\n",
        "print(f\"M√©dia de Precis√£o Sigmoide: {media_sigmoide:.2f}%\")\n",
        "\n",
        "# Precis√µes ReLU\n",
        "precisoes_relu = [47.81, 62.62, 66.06, 72.50, 75.54, 77.53, 78.62, 79.53, 80.17, 81.48]\n",
        "media_relu = sum(precisoes_relu) / len(precisoes_relu)\n",
        "print(f\"M√©dia de Precis√£o ReLU: {media_relu:.2f}%\")\n"
      ],
      "metadata": {
        "id": "0of0EJ0Ar5qa",
        "outputId": "96e16e5b-1538-4575-d149-957e226ef216",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©dia de Precis√£o Sigmoide: 74.30%\n",
            "M√©dia de Precis√£o ReLU: 72.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura da rede com uma camada intermedi√°ria\n",
        "arquitetura = [784, 16, 10]\n",
        "\n",
        "# Taxa de aprendizado a ser testada\n",
        "taxa_aprendizado = 0.5\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: Sigmoid\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o Sigmoid\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_sigmoid = Network(arquitetura)\n",
        "rede_sigmoid.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: ReLU\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o ReLU\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_relu = Network(arquitetura)\n",
        "rede_relu.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)"
      ],
      "metadata": {
        "id": "nhzHPtger2Ef",
        "outputId": "f70bf2a5-9863-44dd-d86b-35d863070563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando fun√ß√£o de ativa√ß√£o Sigmoid\n",
            "Treinando com taxa de aprendizagem: 0.5\n",
            "Epoch 0 : 5046 / 10000 = 50.46%\n",
            "Epoch 1 : 7424 / 10000 = 74.24%\n",
            "Epoch 2 : 8055 / 10000 = 80.55%\n",
            "Epoch 3 : 8358 / 10000 = 83.58%\n",
            "Epoch 4 : 8509 / 10000 = 85.09%\n",
            "Epoch 5 : 8616 / 10000 = 86.16%\n",
            "Epoch 6 : 8686 / 10000 = 86.86%\n",
            "Epoch 7 : 8745 / 10000 = 87.45%\n",
            "Epoch 8 : 8786 / 10000 = 87.86%\n",
            "Epoch 9 : 8824 / 10000 = 88.24%\n",
            "Testando fun√ß√£o de ativa√ß√£o ReLU\n",
            "Treinando com taxa de aprendizagem: 0.5\n",
            "Epoch 0 : 4696 / 10000 = 46.96%\n",
            "Epoch 1 : 6572 / 10000 = 65.72%\n",
            "Epoch 2 : 7162 / 10000 = 71.62%\n",
            "Epoch 3 : 7446 / 10000 = 74.46%\n",
            "Epoch 4 : 7637 / 10000 = 76.37%\n",
            "Epoch 5 : 7748 / 10000 = 77.48%\n",
            "Epoch 6 : 7842 / 10000 = 78.42%\n",
            "Epoch 7 : 7886 / 10000 = 78.86%\n",
            "Epoch 8 : 7928 / 10000 = 79.28%\n",
            "Epoch 9 : 7961 / 10000 = 79.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precis√µes Sigmoide\n",
        "precisoes_sigmoide = [50.46, 74.24, 80.55, 83.58, 85.09, 86.16, 86.86, 87.45, 87.86, 88.24]\n",
        "media_sigmoide = sum(precisoes_sigmoide) / len(precisoes_sigmoide)\n",
        "print(f\"M√©dia de Precis√£o Sigmoide: {media_sigmoide:.2f}%\")\n",
        "\n",
        "# Precis√µes ReLU\n",
        "precisoes_relu = [46.96, 65.72, 71.62, 74.46, 76.37, 77.48, 78.42, 78.86, 79.28, 79.61]\n",
        "media_relu = sum(precisoes_relu) / len(precisoes_relu)\n",
        "print(f\"M√©dia de Precis√£o ReLU: {media_relu:.2f}%\")\n"
      ],
      "metadata": {
        "id": "zrr8ieF6r59G",
        "outputId": "3c7350b2-f651-4ed2-bbf4-ad26fd3b704f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©dia de Precis√£o Sigmoide: 81.05%\n",
            "M√©dia de Precis√£o ReLU: 72.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura da rede com uma camada intermedi√°ria\n",
        "arquitetura = [784, 32, 10]\n",
        "\n",
        "# Taxa de aprendizado a ser testada\n",
        "taxa_aprendizado = 0.1\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: Sigmoid\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o Sigmoid\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_sigmoid = Network(arquitetura)\n",
        "rede_sigmoid.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: ReLU\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o ReLU\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_relu = Network(arquitetura)\n",
        "rede_relu.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)"
      ],
      "metadata": {
        "id": "L2M2IHGStnWP",
        "outputId": "e7fc52fd-72a3-4c0f-e8d1-821679d349ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando fun√ß√£o de ativa√ß√£o Sigmoid\n",
            "Treinando com taxa de aprendizagem: 0.1\n",
            "Epoch 0 : 2971 / 10000 = 29.71%\n",
            "Epoch 1 : 4263 / 10000 = 42.63%\n",
            "Epoch 2 : 5036 / 10000 = 50.36%\n",
            "Epoch 3 : 5700 / 10000 = 57.0%\n",
            "Epoch 4 : 6102 / 10000 = 61.02%\n",
            "Epoch 5 : 6372 / 10000 = 63.72%\n",
            "Epoch 6 : 6563 / 10000 = 65.63%\n",
            "Epoch 7 : 6778 / 10000 = 67.78%\n",
            "Epoch 8 : 7044 / 10000 = 70.44%\n",
            "Epoch 9 : 7268 / 10000 = 72.68%\n",
            "Testando fun√ß√£o de ativa√ß√£o ReLU\n",
            "Treinando com taxa de aprendizagem: 0.1\n",
            "Epoch 0 : 1997 / 10000 = 19.97%\n",
            "Epoch 1 : 2798 / 10000 = 27.98%\n",
            "Epoch 2 : 3800 / 10000 = 38.0%\n",
            "Epoch 3 : 4867 / 10000 = 48.67%\n",
            "Epoch 4 : 5755 / 10000 = 57.55%\n",
            "Epoch 5 : 6229 / 10000 = 62.29%\n",
            "Epoch 6 : 6514 / 10000 = 65.14%\n",
            "Epoch 7 : 6723 / 10000 = 67.23%\n",
            "Epoch 8 : 6896 / 10000 = 68.96%\n",
            "Epoch 9 : 7056 / 10000 = 70.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precis√µes Sigmoide\n",
        "precisoes_sigmoide = [29.71, 42.63, 50.36, 57.00, 61.02, 63.72, 65.63, 67.78, 70.44, 72.68]\n",
        "media_sigmoide = sum(precisoes_sigmoide) / len(precisoes_sigmoide)\n",
        "print(f\"M√©dia de Precis√£o Sigmoide: {media_sigmoide:.2f}%\")\n",
        "\n",
        "# Precis√µes ReLU\n",
        "precisoes_relu = [19.97, 27.98, 38.00, 48.67, 57.55, 62.29, 65.14, 67.23, 68.96, 70.56]\n",
        "media_relu = sum(precisoes_relu) / len(precisoes_relu)\n",
        "print(f\"M√©dia de Precis√£o ReLU: {media_relu:.2f}%\")\n"
      ],
      "metadata": {
        "id": "2baBxRmlt2DW",
        "outputId": "74c08686-d400-42e3-f7bf-bc6393348ee2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©dia de Precis√£o Sigmoide: 58.10%\n",
            "M√©dia de Precis√£o ReLU: 52.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura da rede com uma camada intermedi√°ria\n",
        "arquitetura = [784, 32, 10]\n",
        "\n",
        "# Taxa de aprendizado a ser testada\n",
        "taxa_aprendizado = 0.3\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: Sigmoid\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o Sigmoid\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_sigmoid = Network(arquitetura)\n",
        "rede_sigmoid.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: ReLU\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o ReLU\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_relu = Network(arquitetura)\n",
        "rede_relu.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)"
      ],
      "metadata": {
        "id": "U2Xi6BzitwJJ",
        "outputId": "6c2fb684-183f-4d9d-f789-04453cc8ac7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando fun√ß√£o de ativa√ß√£o Sigmoid\n",
            "Treinando com taxa de aprendizagem: 0.3\n",
            "Epoch 0 : 4862 / 10000 = 48.62%\n",
            "Epoch 1 : 6712 / 10000 = 67.12%\n",
            "Epoch 2 : 7289 / 10000 = 72.89%\n",
            "Epoch 3 : 7608 / 10000 = 76.08%\n",
            "Epoch 4 : 8199 / 10000 = 81.99%\n",
            "Epoch 5 : 8453 / 10000 = 84.53%\n",
            "Epoch 6 : 8558 / 10000 = 85.58%\n",
            "Epoch 7 : 8650 / 10000 = 86.5%\n",
            "Epoch 8 : 8717 / 10000 = 87.17%\n",
            "Epoch 9 : 8755 / 10000 = 87.55%\n",
            "Testando fun√ß√£o de ativa√ß√£o ReLU\n",
            "Treinando com taxa de aprendizagem: 0.3\n",
            "Epoch 0 : 5095 / 10000 = 50.95%\n",
            "Epoch 1 : 6254 / 10000 = 62.54%\n",
            "Epoch 2 : 7379 / 10000 = 73.79%\n",
            "Epoch 3 : 7999 / 10000 = 79.99%\n",
            "Epoch 4 : 8262 / 10000 = 82.62%\n",
            "Epoch 5 : 8444 / 10000 = 84.44%\n",
            "Epoch 6 : 8561 / 10000 = 85.61%\n",
            "Epoch 7 : 8653 / 10000 = 86.53%\n",
            "Epoch 8 : 8722 / 10000 = 87.22%\n",
            "Epoch 9 : 8781 / 10000 = 87.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precis√µes Sigmoide\n",
        "precisoes_sigmoide = [48.62, 67.12, 72.89, 76.08, 81.99, 84.53, 85.58, 86.50, 87.17, 87.55]\n",
        "media_sigmoide = sum(precisoes_sigmoide) / len(precisoes_sigmoide)\n",
        "print(f\"M√©dia de Precis√£o Sigmoide: {media_sigmoide:.2f}%\")\n",
        "\n",
        "# Precis√µes ReLU\n",
        "precisoes_relu = [50.95, 62.54, 73.79, 79.99, 82.62, 84.44, 85.61, 86.53, 87.22, 87.81]\n",
        "media_relu = sum(precisoes_relu) / len(precisoes_relu)\n",
        "print(f\"M√©dia de Precis√£o ReLU: {media_relu:.2f}%\")\n"
      ],
      "metadata": {
        "id": "KVqPPV0zt2fV",
        "outputId": "88a5c168-73b9-4576-bca3-6619ed966359",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©dia de Precis√£o Sigmoide: 77.80%\n",
            "M√©dia de Precis√£o ReLU: 78.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura da rede com uma camada intermedi√°ria\n",
        "arquitetura = [784, 32, 10]\n",
        "\n",
        "# Taxa de aprendizado a ser testada\n",
        "taxa_aprendizado = 0.5\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: Sigmoid\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o Sigmoid\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_sigmoid = Network(arquitetura)\n",
        "rede_sigmoid.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)\n",
        "\n",
        "# Fun√ß√£o de ativa√ß√£o: ReLU\n",
        "print(\"Testando fun√ß√£o de ativa√ß√£o ReLU\")\n",
        "\n",
        "print(f\"Treinando com taxa de aprendizagem: {taxa_aprendizado}\")\n",
        "rede_relu = Network(arquitetura)\n",
        "rede_relu.SGD(training_data, 10, 32, taxa_aprendizado, test_data=test_data_list)"
      ],
      "metadata": {
        "id": "MgAvxQA3twzv",
        "outputId": "4c3b8930-effd-4078-f6a0-e72fe58103f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testando fun√ß√£o de ativa√ß√£o Sigmoid\n",
            "Treinando com taxa de aprendizagem: 0.5\n",
            "Epoch 0 : 5962 / 10000 = 59.62%\n",
            "Epoch 1 : 7579 / 10000 = 75.79%\n",
            "Epoch 2 : 8010 / 10000 = 80.1%\n",
            "Epoch 3 : 8424 / 10000 = 84.24%\n",
            "Epoch 4 : 8635 / 10000 = 86.35%\n",
            "Epoch 5 : 8746 / 10000 = 87.46%\n",
            "Epoch 6 : 8816 / 10000 = 88.16%\n",
            "Epoch 7 : 8874 / 10000 = 88.74%\n",
            "Epoch 8 : 8899 / 10000 = 88.99%\n",
            "Epoch 9 : 8957 / 10000 = 89.57%\n",
            "Testando fun√ß√£o de ativa√ß√£o ReLU\n",
            "Treinando com taxa de aprendizagem: 0.5\n",
            "Epoch 0 : 5378 / 10000 = 53.78%\n",
            "Epoch 1 : 6661 / 10000 = 66.61%\n",
            "Epoch 2 : 7198 / 10000 = 71.98%\n",
            "Epoch 3 : 7455 / 10000 = 74.55%\n",
            "Epoch 4 : 7607 / 10000 = 76.07%\n",
            "Epoch 5 : 8614 / 10000 = 86.14%\n",
            "Epoch 6 : 8795 / 10000 = 87.95%\n",
            "Epoch 7 : 8857 / 10000 = 88.57%\n",
            "Epoch 8 : 8910 / 10000 = 89.1%\n",
            "Epoch 9 : 8951 / 10000 = 89.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precis√µes Sigmoide\n",
        "precisoes_sigmoide = [59.62, 75.79, 80.10, 84.24, 86.35, 87.46, 88.16, 88.74, 88.99, 89.57]\n",
        "media_sigmoide = sum(precisoes_sigmoide) / len(precisoes_sigmoide)\n",
        "print(f\"M√©dia de Precis√£o Sigmoide: {media_sigmoide:.2f}%\")\n",
        "\n",
        "# Precis√µes ReLU\n",
        "precisoes_relu = [53.78, 66.61, 71.98, 74.55, 76.07, 86.14, 87.95, 88.57, 89.10, 89.51]\n",
        "media_relu = sum(precisoes_relu) / len(precisoes_relu)\n",
        "print(f\"M√©dia de Precis√£o ReLU: {media_relu:.2f}%\")\n"
      ],
      "metadata": {
        "id": "QH4lcPFCt203",
        "outputId": "707ca9ab-42b9-4701-e69a-64d2ca50e9e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M√©dia de Precis√£o Sigmoide: 82.90%\n",
            "M√©dia de Precis√£o ReLU: 78.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2V5r3YW95A4"
      },
      "source": [
        "#Executa a rede neural\n",
        "\n",
        "Par√¢metros de rede:\n",
        "         2¬∫ param √© contagem de √©pocas\n",
        "         3¬∫ param √© tamanho do lote\n",
        "         4¬∫ param √© a taxa de aprendizado (ùúÇ)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c86ya6KrquI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "aceaffaf-faea-4419-f4f0-cb78c8969c97"
      },
      "source": [
        "training_data, validation_data, test_data = load_data_wrapper()\n",
        "training_data = list(training_data)\n",
        "\n",
        "#arquitetura da rede\n",
        "arquitecture = [784, 30, 20, 10]\n",
        "mlp = Network(arquitecture)\n",
        "mlp.SGD(training_data, 10, 32, 0.3, test_data=test_data)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 : 4984 / 10000 = 49.84%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e4a093439879>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0marquitecture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marquitecture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-bbbe4cba2592>\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, training_data, epochs, mini_batch_size, Œ∑, test_data)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmini_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mùúÇ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-bbbe4cba2592>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, mini_batch, Œ∑)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m#resultado dos deltas do backpropagation sem a multiplica√ß√£o da taxa de aprendizagem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m#soma os deltas do minibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mdelta_nabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_nabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdnw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnabla_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_nabla_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnabla_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdnb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_nabla_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-bbbe4cba2592>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mnets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#z = valor de sa√≠da do neur√¥nio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLJbbYrFdU_w"
      },
      "source": [
        "##**Mini-Projeto**\n",
        "1) Realizar avalia√ß√µes modificando os seguintes par√¢metros:     \n",
        "\n",
        "     a) Taxa de aprendizagem: 0.1, 0.3 e 0.5\n",
        "     b) Fun√ß√£o de ativa√ß√£o RELU\n",
        "     c) Rede com uma camada intermedi√°ria com 3 configura√ß√µes diferentes (Explicite a configura√ß√£o utilizada)\n",
        "     d) Rede com duas camadas intermedi√°rias com 3 configura√ß√µes diferentes (Explicite a configura√ß√£o utilizada)\n",
        "     \n",
        "      \n",
        "Complete a Tabela abaixo com os resultados (Pra cada configura√ß√£o de camadas intermedi√°rias, execute as 3 taxas de aprendizagem pra fun√ß√£o de ativa√ß√£o Sigmoide e Relu):\n",
        "\n",
        "\n",
        "\\begin{array}{|c|ccc|ccc|ccc|}\\hline\\\\ \\\\\n",
        "  1\\;Camada\\;Intermedi√°ria & & \\mathcal{ùúÇ=0.1} & &  & \\mathcal{ùúÇ=0.3} & & & \\mathcal{ùúÇ=0.5} &  & \\\\ \\hline\n",
        "Configura√ß√µes & [784, 16, 10], [784, 32, 10], [784, 64, 10] &&&[784, 16, 10], [784, 32, 10], [784, 64, 10] &&&[784, 16, 10], [784, 32, 10], [784, 64, 10]\\\\ \\hline\n",
        "Sigmoide  & & & &a &  & & &  &  & \\\\ \\hline\n",
        "Relu  & & & &a  &  & & &  &  & \\\\ \\hline\n",
        "  2\\;Camadas\\;Intermedi√°rias & & \\mathcal{ùúÇ=0.1} & &  & \\mathcal{ùúÇ=0.3} & & & \\mathcal{ùúÇ=0.5} &  & \\\\ \\hline\n",
        "Configura√ß√µes & 1 & 2 & 3 & 1 & 2 & 3 & 1 & 2 & 3 & \\\\ \\hline\n",
        "Sigmoide  & & & &  &  & & &  &  & \\\\ \\hline\n",
        "Relu  & & & &  &  & & &  &  & \\\\ \\hline\n",
        "\\end{array}\n",
        "\n",
        "2) Modifique a taxa de aprendizagem pra diminuir com o tempo. Execute com a melhor configura√ß√£o encontrada. Melhorou o resultado?\n"
      ]
    }
  ]
}